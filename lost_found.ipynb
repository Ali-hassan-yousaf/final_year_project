{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFa2gKJ/6IJENHsoQHIuoE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-hassan-yousaf/final_year_project/blob/main/lost_found.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "-QDsWf8b58Ay",
        "outputId": "028e83c9-f0f6-46ae-b93a-e9a67605048a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 145MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e5d0557481cec0606c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e5d0557481cec0606c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -q gradio faiss-cpu torch torchvision Pillow numpy\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import os\n",
        "import faiss\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import datetime\n",
        "\n",
        "# Initialize model for feature extraction\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "model = model.to(device).eval()\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PetFinderAPI:\n",
        "    def __init__(self):\n",
        "        self.index = faiss.IndexFlatL2(2048)  # ResNet50 feature dimension\n",
        "        self.image_data = []\n",
        "        self.image_dir = \"pet_images\"\n",
        "        os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "    def extract_features(self, image_np):\n",
        "        img = Image.fromarray(image_np).convert('RGB')\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            features = model(img_tensor)\n",
        "        return features.cpu().numpy().flatten()\n",
        "\n",
        "    def add_found_pet(self, image_np, filename, found_location, pet_type, phone_number, notes):\n",
        "        try:\n",
        "            # Save image\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            save_filename = f\"{timestamp}_{filename}\"\n",
        "            save_path = os.path.join(self.image_dir, save_filename)\n",
        "            Image.fromarray(image_np).save(save_path)\n",
        "\n",
        "            # Extract and store features\n",
        "            features = self.extract_features(image_np)\n",
        "            self.image_data.append({\n",
        "                \"image\": image_np,\n",
        "                \"filename\": save_filename,\n",
        "                \"features\": features,\n",
        "                \"found_location\": found_location,\n",
        "                \"pet_type\": pet_type,\n",
        "                \"phone_number\": phone_number,\n",
        "                \"notes\": notes,\n",
        "                \"timestamp\": timestamp\n",
        "            })\n",
        "\n",
        "            # Update FAISS index\n",
        "            if len(self.image_data) == 1:\n",
        "                self.index.add(np.array([features]))\n",
        "            else:\n",
        "                self.index.add(np.array([features]))\n",
        "\n",
        "            return save_path, f\"✅ Pet added successfully!\\nSaved as: {save_filename}\"\n",
        "        except Exception as e:\n",
        "            return None, f\"❌ Error: {str(e)}\"\n",
        "\n",
        "    def search_lost_pet(self, query_image_np):\n",
        "        try:\n",
        "            if not self.image_data:\n",
        "                return [], \"⚠️ Database is empty. Please add pets first.\"\n",
        "\n",
        "            # Extract query features\n",
        "            query_features = self.extract_features(query_image_np)\n",
        "\n",
        "            # Search in FAISS index\n",
        "            distances, indices = self.index.search(np.array([query_features]), 3)\n",
        "\n",
        "            # Prepare results\n",
        "            results = []\n",
        "            for idx, score in zip(indices[0], distances[0]):\n",
        "                if idx >= 0:  # FAISS returns -1 for invalid indices\n",
        "                    result = self.image_data[idx].copy()\n",
        "                    result['score'] = 1 / (1 + score)  # Convert distance to similarity score\n",
        "                    results.append(result)\n",
        "\n",
        "            if not results:\n",
        "                return results, \"🔍 No matches found. Try another image.\"\n",
        "\n",
        "            return results, f\"🔎 Found {len(results)} potential matches!\"\n",
        "        except Exception as e:\n",
        "            return [], f\"❌ Search error: {str(e)}\"\n",
        "\n",
        "# Initialize API\n",
        "pet_api = PetFinderAPI()\n",
        "\n",
        "# Gradio Functions\n",
        "def add_found_pet_gr(image, found_location, pet_type, phone_number, notes):\n",
        "    image_np = np.array(image)\n",
        "    save_path, msg = pet_api.add_found_pet(\n",
        "        image_np,\n",
        "        \"uploaded.jpg\",\n",
        "        found_location,\n",
        "        pet_type,\n",
        "        phone_number,\n",
        "        notes\n",
        "    )\n",
        "    return msg\n",
        "\n",
        "def search_lost_pet_gr(query_image):\n",
        "    query_np = np.array(query_image)\n",
        "    results, msg = pet_api.search_lost_pet(query_np)\n",
        "\n",
        "    # Prepare outputs\n",
        "    images = [None, None, None]\n",
        "    details = [\"\", \"\", \"\"]\n",
        "\n",
        "    if results:\n",
        "        for i, r in enumerate(results[:3]):\n",
        "            images[i] = Image.fromarray(r['image'])\n",
        "            details[i] = (\n",
        "                f\"🐾 Type: {r.get('pet_type', 'N/A')}\\n\"\n",
        "                f\"📍 Location: {r.get('found_location', 'N/A')}\\n\"\n",
        "                f\"📞 Contact: {r.get('phone_number', 'N/A')}\\n\"\n",
        "                f\"📝 Notes: {r.get('notes', 'N/A')}\\n\"\n",
        "                f\"⏰ Reported: {r.get('timestamp', 'N/A')}\"\n",
        "            )\n",
        "\n",
        "    return msg, images[0], images[1], images[2], details[0], details[1], details[2]\n",
        "\n",
        "# Custom Theme with #5e5eee Colored Buttons\n",
        "theme = gr.themes.Soft(\n",
        "    primary_hue=\"indigo\",\n",
        "    secondary_hue=\"gray\",\n",
        "    font=[gr.themes.GoogleFont(\"Montserrat\")]\n",
        ").set(\n",
        "    button_primary_background_fill=\"#5e5eee\",       # Main button color\n",
        "    button_primary_background_fill_hover=\"#4a4ae0\",  # Slightly darker on hover\n",
        "    button_primary_text_color=\"#ffffff\",             # White text\n",
        "    button_primary_background_fill_dark=\"#5e5eee\",   # Same for dark mode\n",
        "    button_primary_border_color=\"#5e5eee\",\n",
        "    button_primary_border_color_dark=\"#5e5eee\",\n",
        "    button_primary_border_color_hover=\"#4a4ae0\"\n",
        ")\n",
        "\n",
        "# Create Interface\n",
        "with gr.Blocks(theme=theme, title=\"Pet Finder\") as demo:\n",
        "    gr.Markdown(\"# 🐾 Lost & Found\")\n",
        "\n",
        "\n",
        "    with gr.Tab(\"🔍 Search Lost Pet\", id=\"search_tab\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                search_input = gr.Image(type=\"pil\", label=\"Upload photo of lost pet\", sources=[\"upload\", \"webcam\"])\n",
        "                search_btn = gr.Button(\"Search Database\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                search_output_text = gr.Textbox(label=\"Results\", interactive=False)\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        search_output1 = gr.Image(label=\"Top Match\", show_label=True)\n",
        "                        # Added scrollable text area with fixed height\n",
        "                        search_detail1 = gr.Textbox(label=\"Details\", interactive=False, show_label=True, lines=5, max_lines=10)\n",
        "                    with gr.Column():\n",
        "                        search_output2 = gr.Image(label=\"Second Match\", show_label=True)\n",
        "                        # Added scrollable text area with fixed height\n",
        "                        search_detail2 = gr.Textbox(label=\"Details\", interactive=False, show_label=True, lines=5, max_lines=10)\n",
        "                    with gr.Column():\n",
        "                        search_output3 = gr.Image(label=\"Third Match\", show_label=True)\n",
        "                        # Added scrollable text area with fixed height\n",
        "                        search_detail3 = gr.Textbox(label=\"Details\", interactive=False, show_label=True, lines=5, max_lines=10)\n",
        "\n",
        "        search_btn.click(\n",
        "            search_lost_pet_gr,\n",
        "            inputs=search_input,\n",
        "            outputs=[\n",
        "                search_output_text,\n",
        "                search_output1,\n",
        "                search_output2,\n",
        "                search_output3,\n",
        "                search_detail1,\n",
        "                search_detail2,\n",
        "                search_detail3\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"📸 Add Found Pet\", id=\"add_tab\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                add_input = gr.Image(type=\"pil\", label=\"Upload photo of found pet\", sources=[\"upload\", \"webcam\"])\n",
        "                found_location = gr.Textbox(label=\"Found Location\", placeholder=\"Where was the pet found?\")\n",
        "                with gr.Row():\n",
        "                    pet_type = gr.Dropdown(\n",
        "                        [\"Dog\", \"Cat\", \"Bird\", \"Rabbit\", \"Other\"],\n",
        "                        label=\"Pet Type\",\n",
        "                        value=\"Dog\"\n",
        "                    )\n",
        "                    phone_number = gr.Textbox(label=\"Contact Phone\", placeholder=\"Your phone number\")\n",
        "                # Added scrollable text area for notes with fixed height\n",
        "                notes = gr.Textbox(label=\"Additional Notes\", placeholder=\"Color, collar, condition, etc.\", lines=3)\n",
        "                add_btn = gr.Button(\"Add to Database\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                add_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "        add_btn.click(\n",
        "            add_found_pet_gr,\n",
        "            inputs=[add_input, found_location, pet_type, phone_number, notes],\n",
        "            outputs=add_output\n",
        "        )\n",
        "\n",
        "    gr.Markdown(\"---\\n> ℹ️ Tips: Use clear, well-lit photos for best results\")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wait"
      ],
      "metadata": {
        "id": "QtufJSKp6lhC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}